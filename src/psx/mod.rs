//! Top level for the emulation code. Contains the state of the emulated console.

pub mod bios;
pub mod cd;
pub mod compatibility;
pub mod cop0;
pub mod cop0_enhanced;
pub mod cpu;
pub mod cpu_instructions;
pub mod cpu_pipeline;
pub mod cpu_pipeline_integration;
pub mod cpu_timing;
#[cfg(test)]
mod cpu_pipeline_tests;
#[cfg(feature = "debugger")]
pub mod debugger;
mod cache;
mod dma;
mod expansion;
pub mod gpu;
pub mod ggpo;
mod gte;
mod irq;
mod link_cable;
mod mdec;
mod memory_bus;
mod memory_control;
pub mod memory_map;
#[cfg(feature = "pgxp")]
pub mod pgxp;
#[cfg(feature = "ml-input-prediction")]
pub mod ml_input_prediction;
pub mod overlay;
pub mod pad_memcard;
mod spu;
mod sync;
mod timers;
mod vram;
mod xmem;
pub mod zram;
pub mod zram_config;
pub mod run_ahead;
pub mod fast_savestate;
pub mod run_ahead_integration;
pub mod power_management;
pub mod framerate_controller;
pub mod display_sync;
pub mod retroachievements;
pub mod security;

// ARM-specific optimizations
#[cfg(target_arch = "aarch64")]
pub mod arm_optimizer;

use crate::error::{PsxError, Result};
pub use cd::{disc, iso9660, CDC_ROM_SHA256, CDC_ROM_SIZE};
pub use gpu::{Frame, VideoStandard};
pub use overlay::{DeveloperOverlay, renderer::OverlayRenderData};
pub use spu::{SpuDebugOverlay, interpolation};
pub use zram::{ZramSystem, GpuMemoryCompressor, CompressionStats};
use serde::de::{Deserialize, Deserializer};
use std::cmp::min;

/// Type alias used to represent a number of clock cycles
pub type CycleCount = i32;

/// Current state of the emulator
#[derive(serde::Serialize, serde::Deserialize)]
pub struct Psx {
    /// Counter of the number of CPU cycles elapsed since an arbitrary point in time. Used as the
    /// reference to synchronize the other modules
    cycle_counter: CycleCount,
    /// Set to true when the GPU is done drawing one frame (or one field in interlaced mode)
    frame_done: bool,
    sync: sync::Synchronizer,
    pub cpu: cpu::Cpu,
    pub cop0: cop0::Cop0,
    pub gte: gte::Gte,
    irq: irq::InterruptState,
    /// Executable memory: RAM, Bios etc...
    xmem: xmem::XMemory,
    scratch_pad: ScratchPad,
    pub spu: spu::Spu,
    dma: dma::Dma,
    timers: timers::Timers,
    pub gpu: gpu::Gpu,
    mdec: mdec::MDec,
    pub cd: cd::CdInterface,
    pub pad_memcard: pad_memcard::PadMemCard,
    /// Expansion port controller
    expansion: expansion::ExpansionPort,
    /// Link cable controller
    link_cable: link_cable::LinkCable,
    /// Enhanced cache system
    cache_system: cache::CacheSystem,
    /// Enhanced memory control
    memory_ctrl: memory_control::MemoryControl,
    /// Unified Memory Bus controller
    memory_bus: memory_bus::MemoryBus,
    /// Unified VRAM controller
    vram: vram::Vram,
    /// Cache coherency manager
    cache_coherency: memory_bus::CacheCoherency,
    /// PGXP precision enhancement system
    #[cfg(feature = "pgxp")]
    #[serde(skip)]
    pub pgxp: pgxp::Pgxp,
    /// Memory control registers (legacy)
    mem_control: [u32; 9],
    /// Contents of the RAM_SIZE register which is probably a configuration register for the memory
    /// controller.
    ram_size: u32,
    /// Contents of the CACHE_CONTROL register
    cache_control: u32,
    /// Used to simulate the CPU slowdown generated by DMA operation
    dma_timing_penalty: CycleCount,
    /// When this variable is `true` the CPU is stopped for DMA operation
    cpu_stalled_for_dma: bool,
    /// Developer overlay system (not serialized)
    #[serde(skip)]
    developer_overlay: overlay::DeveloperOverlay,
    /// ZRAM memory compression system (not serialized)
    #[serde(skip)]
    zram_system: zram::ZramSystem,
    /// GPU memory compressor (not serialized)
    #[serde(skip)]
    gpu_compressor: zram::GpuMemoryCompressor,
    /// Game compatibility manager (not serialized)
    #[serde(skip)]
    compatibility_manager: compatibility::CompatibilityManager,
    /// GGPO netplay session (not serialized)
    #[serde(skip)]
    ggpo_session: Option<ggpo::GgpoSession>,
    /// Dynamic power management system
    #[serde(skip)]
    pub power_management: Option<power_management::PowerManagement>,
    /// Framerate controller
    #[serde(skip)]
    pub framerate_controller: Option<framerate_controller::FramerateController>,
    /// Display synchronization
    #[serde(skip)]
    pub display_sync: Option<display_sync::DisplaySync>,
    /// ARM optimization system (not serialized)
    #[cfg(target_arch = "aarch64")]
    #[serde(skip)]
    arm_optimizer: arm_optimizer::ArmOptimizer,
}

impl Psx {
    pub fn new_with_disc(
        disc: disc::Disc,
        bios: bios::Bios,
        cdc_firmware: [u8; cd::CDC_ROM_SIZE],
    ) -> Result<Psx> {
        let standard = disc.region().video_standard();
        let serial = disc.serial_number();

        let mut psx = Psx::new_with_bios(Some(disc), bios, standard, cdc_firmware)?;
        
        // Detect game and apply compatibility patches
        psx.compatibility_manager.detect_game(serial);
        let profile = psx.compatibility_manager.current_profile().clone();
        psx.apply_game_patches(&profile);
        
        Ok(psx)
    }

    pub fn new_with_bios(
        disc: Option<disc::Disc>,
        bios: bios::Bios,
        standard: gpu::VideoStandard,
        cdc_firmware: [u8; cd::CDC_ROM_SIZE],
    ) -> Result<Psx> {
        let mut xmem = xmem::XMemory::new();

        xmem.set_bios(bios.get_rom());

        let cd = cd::CdInterface::new(disc, cdc_firmware)?;

        Ok(Psx {
            cycle_counter: 0,
            frame_done: false,
            sync: sync::Synchronizer::new(),
            cpu: cpu::Cpu::new(),
            cop0: cop0::Cop0::new(),
            gte: gte::Gte::new(),
            irq: irq::InterruptState::new(),
            xmem,
            scratch_pad: ScratchPad::new(),
            spu: spu::Spu::new(),
            dma: dma::Dma::new(),
            timers: timers::Timers::new(),
            gpu: gpu::Gpu::new(standard),
            mdec: mdec::MDec::new(),
            cd,
            pad_memcard: pad_memcard::PadMemCard::new(),
            expansion: expansion::ExpansionPort::new(),
            link_cable: link_cable::LinkCable::new(),
            cache_system: cache::CacheSystem::new(),
            memory_ctrl: memory_control::MemoryControl::new(),
            memory_bus: memory_bus::MemoryBus::new(),
            vram: vram::Vram::new(),
            cache_coherency: memory_bus::CacheCoherency::new(),
            #[cfg(feature = "pgxp")]
            pgxp: pgxp::Pgxp::new(),
            mem_control: [0; 9],
            ram_size: 0,
            cache_control: 0,
            dma_timing_penalty: 0,
            cpu_stalled_for_dma: false,
            developer_overlay: overlay::DeveloperOverlay::new(),
            zram_system: zram::ZramSystem::new(4096, num_cpus::get()),
            gpu_compressor: zram::GpuMemoryCompressor::new(),
            compatibility_manager: compatibility::CompatibilityManager::new(),
            ggpo_session: None,
            power_management: Some(power_management::PowerManagement::new()),
            framerate_controller: Some(framerate_controller::FramerateController::new()),
            display_sync: Some(display_sync::DisplaySync::new()),
            #[cfg(target_arch = "aarch64")]
            arm_optimizer: {
                let mut optimizer = arm_optimizer::ArmOptimizer::new();
                optimizer.initialize();
                optimizer
            },
        })
    }

    /// Deserialize a Psx from the given object and transfer our disc, BIOS and CDC ROM to it, then
    /// replace our current state with the deserialized one.
    ///
    /// Will generate an error if there's a mismatch (that is, if the serialized Psx used a
    /// different disc, BIOS or ROM). In this case the state remains unchanged.
    pub fn deserialize_and_load<'de, D>(&mut self, reader: D) -> Result<()>
    where
        D: Deserializer<'de>,
    {
        let mut psx = Box::<Psx>::deserialize(reader)
            .map_err(|e| PsxError::DeserializationError(format!("{}", e)))?;

        psx.xmem.copy_bios(&self.xmem)?;
        psx.cd.cdc.copy_rom(&self.cd.cdc);

        if let Err((e, disc)) = psx.cd.cdc.set_disc(self.cd.cdc.take_disc()) {
            // Take the disc back
            self.cd
                .cdc
                .set_disc(disc)
                .map_err(|(e, _d)| e)
                .expect("Couldn't reload the disc!");

            return Err(e);
        }

        // Move pads to the new instance
        {
            let mut old_pads = self.pad_memcard.gamepads_mut();
            let mut new_pads = psx.pad_memcard.gamepads_mut();

            for (old, new) in old_pads.iter_mut().zip(new_pads.iter_mut()) {
                let pad = old.disconnect_device();
                new.connect_device(pad);
            }
        }

        // Move memory cards to the new instance
        {
            let mut old_mc = self.pad_memcard.memory_cards_mut();
            let mut new_mc = psx.pad_memcard.memory_cards_mut();

            for (old, new) in old_mc.iter_mut().zip(new_mc.iter_mut()) {
                let mc = old.disconnect_device();
                new.connect_device(mc);
            }
        }

        *self = *psx;

        Ok(())
    }

    pub fn video_standard(&self) -> VideoStandard {
        self.gpu.video_standard()
    }

    /// Check if a frame is ready
    pub fn frame_ready(&self) -> bool {
        self.frame_done
    }

    /// Get the current frame
    pub fn get_frame(&self) -> Frame {
        self.gpu.get_frame()
    }

    /// Step the emulator by one CPU instruction or event
    pub fn step(&mut self) {
        if self.cpu_stalled_for_dma {
            // Fast forward to the next event
            self.cycle_counter = self.sync.first_event();
        } else {
            if !sync::is_event_pending(self) {
                cpu::run_next_instruction(self);
            }
        }

        if sync::is_event_pending(self) {
            sync::handle_events(self);
        }
    }

    /// Run the emulator for a single frame
    pub fn run_frame(&mut self) {
        use std::time::Instant;
        let frame_start = Instant::now();
        
        self.frame_done = false;
        while !self.frame_done {
            self.step();
            // Process memory bus for this cycle
            let bus_cycles = self.memory_bus.tick(self.cycle_counter);
            self.tick(bus_cycles);

            if self.cpu_stalled_for_dma {
                // Fast forward to the next event
                self.cycle_counter = self.sync.first_event();
            } else {
                while !sync::is_event_pending(self) {
                    cpu::run_next_instruction(self);
                }
            }

            sync::handle_events(self);
        }

        // Update frame timing stats
        let frame_time = frame_start.elapsed();
        if let Some(fc) = self.framerate_controller.as_mut() {
            if fc.should_present_frame() {
                fc.frame_presented();
            }
        }
        
        // Update display sync
        if let Some(ds) = self.display_sync.as_mut() {
            ds.update(frame_time);
        }
        
        // Update power management metrics
        if let Some(pm) = self.power_management.as_mut() {
            let fps = 1.0 / frame_time.as_secs_f32();
            let frame_time_ms = frame_time.as_secs_f32() * 1000.0;
            pm.update_metrics(fps, frame_time_ms);
        }

        // Update developer overlay if enabled
        if self.developer_overlay.is_enabled() {
            self.update_developer_overlay(self.cycle_counter);
        }

        // Rebase the event counters relative to the cycle_counter to make sure they don't overflow
        sync::rebase_counters(self);
    }

    pub fn take_frame(&mut self) -> Option<Frame> {
        self.gpu.take_frame()
    }

    /// Get pending audio samples since the last call to `clear_audio_samples`
    pub fn get_audio_samples(&mut self) -> &[i16] {
        spu::get_samples(self)
    }

    /// Clear any pending audio samples. This must be called at least once per frame.
    pub fn clear_audio_samples(&mut self) {
        spu::clear_samples(self)
    }

    /// Set SPU interpolation method
    pub fn set_spu_interpolation_method(&mut self, method: spu::interpolation::InterpolationMethod) {
        self.spu.set_interpolation_method(method);
    }

    /// Get current SPU interpolation method
    pub fn get_spu_interpolation_method(&self) -> spu::interpolation::InterpolationMethod {
        self.spu.get_interpolation_method()
    }

    /// Set SPU interpolation configuration
    pub fn set_spu_interpolation_config(&mut self, config: spu::interpolation::InterpolationConfig) {
        self.spu.set_interpolation_config(config);
    }

    /// Get SPU interpolation configuration
    pub fn get_spu_interpolation_config(&self) -> &spu::interpolation::InterpolationConfig {
        self.spu.get_interpolation_config()
    }

    /// Set game ID for SPU interpolation profiles
    pub fn set_game_id_for_spu(&mut self, game_id: String) {
        self.spu.set_game_id(game_id);
    }

    /// Add custom SPU interpolation game profile
    pub fn add_spu_game_profile(&mut self, profile: spu::interpolation::GameProfile) {
        self.spu.add_game_profile(profile);
    }

    /// Set the internal resolution upscaling factor
    /// 0 = 1x (native), 1 = 2x, 2 = 4x, etc.
    pub fn set_upscale_shift(&mut self, shift: u8) {
        self.gpu.set_upscale_shift(shift);
    }

    /// Enable or disable SPU reverb
    pub fn set_spu_reverb_enable(&mut self, enable: bool) {
        self.spu.set_reverb_enable(enable);
    }

    /// Enable or disable enhanced SPU reverb mode for better audio quality
    pub fn set_spu_reverb_enhanced(&mut self, enhanced: bool) {
        self.spu.set_reverb_enhanced(enhanced);
    }

    /// Enable or disable SPU debug overlay
    pub fn enable_spu_debug_overlay(&mut self, enable: bool) {
        self.spu.enable_debug_overlay(enable);
    }

    /// Get SPU debug overlay data if enabled
    pub fn get_spu_debug_overlay(&self) -> Option<&spu::SpuDebugOverlay> {
        self.spu.get_debug_overlay()
    }

    /// Enable or disable the developer overlay
    pub fn set_developer_overlay_enabled(&mut self, enabled: bool) {
        self.developer_overlay.set_enabled(enabled);
    }

    /// Check if developer overlay is enabled
    pub fn is_developer_overlay_enabled(&self) -> bool {
        self.developer_overlay.is_enabled()
    }

    /// Get the developer overlay for configuration
    pub fn developer_overlay_mut(&mut self) -> &mut overlay::DeveloperOverlay {
        &mut self.developer_overlay
    }

    /// Get the developer overlay render data
    pub fn get_developer_overlay_render_data(&self) -> overlay::renderer::OverlayRenderData {
        let renderer = overlay::renderer::OverlayRenderer::new();
        renderer.render(&self.developer_overlay)
    }

    /// Update developer overlay metrics
    fn update_developer_overlay(&mut self, elapsed_cycles: CycleCount) {
        self.developer_overlay.update(self, elapsed_cycles);
    }

    /// Compress memory block using ZRAM
    pub fn compress_memory_block(&self, block_id: usize, data: &[u8], data_type: zram::DataType) -> f32 {
        self.zram_system.store_compressed(block_id, data, data_type)
    }

    /// Decompress memory block from ZRAM
    pub fn decompress_memory_block(&self, block_id: usize) -> Option<Vec<u8>> {
        self.zram_system.retrieve_decompressed(block_id)
    }

    /// Prefetch memory blocks for reduced latency
    pub fn prefetch_memory_blocks(&self, block_ids: &[usize]) {
        self.zram_system.prefetch(block_ids)
    }

    /// Get ZRAM compression statistics
    pub fn get_zram_stats(&self) -> zram::CompressionStats {
        self.zram_system.get_stats()
    }

    /// Get ZRAM memory usage (compressed_size, original_size)
    pub fn get_zram_memory_usage(&self) -> (usize, usize) {
        self.zram_system.get_memory_usage()
    }

    /// Compress GPU texture
    pub fn compress_gpu_texture(&self, texture_id: u64, data: &[u8]) -> f32 {
        self.gpu_compressor.compress_texture(texture_id, data)
    }

    /// Decompress GPU texture
    pub fn decompress_gpu_texture(&self, texture_id: u64) -> Option<Vec<u8>> {
        self.gpu_compressor.decompress_texture(texture_id)
    }

    /// Compress GPU framebuffer
    pub fn compress_gpu_framebuffer(&self, fb_id: usize, data: &[u8]) -> f32 {
        self.gpu_compressor.compress_framebuffer(fb_id, data)
    }

    /// Clear ZRAM compression cache
    pub fn clear_zram_cache(&self) {
        self.zram_system.clear()
    }
    
    /// Update power management system
    pub fn update_power_management(&mut self, has_input: bool, temperature: f32) {
        if let Some(pm) = self.power_management.as_mut() {
            pm.update_idle(has_input);
            pm.check_thermal(temperature);
            
            // Apply CPU frequency scaling
            let cpu_freq_multiplier = pm.get_cpu_frequency_mhz() as f32 / 2400.0;
            self.cpu.frequency_multiplier = cpu_freq_multiplier;
            
            // Apply GPU clock scaling
            let gpu_clock_multiplier = pm.get_gpu_clock_mhz() as f32 / 800.0;
            self.gpu.clock_multiplier = gpu_clock_multiplier;
        }
    }

    /// Check if frame should be presented based on power management settings
    pub fn should_present_frame_pm(&mut self) -> bool {
        self.power_management.as_mut()
            .map(|pm| pm.should_present_frame())
            .unwrap_or(true)
    }

    /// Enable fast-forward mode with power boost
    pub fn enable_fast_forward(&mut self) {
        if let Some(pm) = self.power_management.as_mut() {
            pm.enable_fast_forward();
        }
    }

    /// Disable fast-forward mode
    pub fn disable_fast_forward(&mut self) {
        if let Some(pm) = self.power_management.as_mut() {
            pm.disable_fast_forward();
        }
    }

    /// Load a game-specific power profile
    pub fn load_power_profile(&mut self, game_id: &str) {
        if let Some(pm) = self.power_management.as_mut() {
            pm.load_game_profile(game_id);
        }
    }

    /// Save current power settings as a game profile
    pub fn save_power_profile(&mut self, game_id: String, name: String) {
        if let Some(pm) = self.power_management.as_mut() {
            pm.save_game_profile(game_id, name);
        }
    }

    /// Set framerate cap
    pub fn set_framerate_cap(&mut self, cap: power_management::FramerateCap) {
        if let Some(fc) = self.framerate_controller.as_mut() {
            fc.set_target_fps(match cap {
                power_management::FramerateCap::Fps30 => 30.0,
                power_management::FramerateCap::Fps40 => 40.0,
                power_management::FramerateCap::Fps60 => 60.0,
                power_management::FramerateCap::Uncapped => 120.0,
                power_management::FramerateCap::Custom(fps) => fps as f32,
            });
        }
    }

    /// Set display refresh rate
    pub fn set_refresh_rate(&mut self, rate: f32) {
        if let Some(ds) = self.display_sync.as_mut() {
            ds.set_refresh_rate(rate);
        }
        if let Some(fc) = self.framerate_controller.as_mut() {
            fc.set_refresh_rate(rate);
        }
    }

    /// Enable/disable VRR
    pub fn set_vrr_enabled(&mut self, enabled: bool) {
        if let Some(ds) = self.display_sync.as_mut() {
            ds.set_vrr_enabled(enabled);
        }
    }

    /// Update battery information
    pub fn update_battery(&mut self, charge_percent: f32, is_charging: bool, current_draw_ma: f32) {
        if let Some(pm) = self.power_management.as_mut() {
            pm.update_battery(charge_percent, is_charging, current_draw_ma);
        }
    }

    /// Get power management metrics
    pub fn get_power_metrics(&self) -> Option<&power_management::PerformanceMetrics> {
        self.power_management.as_ref().map(|pm| &pm.metrics)
    }

    /// Get battery information
    pub fn get_battery_info(&self) -> Option<&power_management::BatteryInfo> {
        self.power_management.as_ref().map(|pm| &pm.battery_info)
    }

    /// Apply OLED optimizations to a frame
    pub fn apply_oled_optimizations(&self, frame: &mut [u8], width: usize, height: usize) {
        if let Some(pm) = self.power_management.as_ref() {
            pm.apply_oled_optimizations(frame, width, height);
        }
    }

    /// Advance the CPU cycle counter by the given number of ticks
    fn tick(&mut self, cycles: CycleCount) {
        self.cycle_counter += cycles;
    }

    /// Like load, but tries to minimizes side-effects. Used for debugging.
    #[cfg(feature = "debugger")]
    pub fn examine<T: Addressable>(&mut self, address: u32) -> T {
        // A bit heavy handed but that shouldn't pose much of a problem since this function should
        // only be used for debugging. Catching unwinds means that it will be harder for the
        // debugger to crash the emulator if it triggers an unhandled edge case (in particular if
        // it attempts to read from some unimplemented memory location).
        use ::std::panic;

        let cc = self.cycle_counter;

        let result = panic::catch_unwind(panic::AssertUnwindSafe(|| self.load(address)));

        // Restore the previous counter to avoid advancing the emulation state with debug reads
        self.cycle_counter = cc;

        let bad_value = Addressable::from_u32(0xfbad_c0de);

        result.unwrap_or(bad_value)
    }

    /// Decode `address` and perform the load from the target module. `cc` contains the value of
    /// the CPU cycle counter when the transfer begins and should be updated to contain the value
    /// of the cycle counter when it'll complete.
    fn load<T: Addressable>(&mut self, address: u32) -> T {
        let abs_addr = map::mask_region(address);

        // Apply memory mirroring
        let physical_addr = self.memory_bus.apply_mirroring(abs_addr);

        // Submit memory request to unified bus
        self.memory_bus.request_access(
            memory_bus::BusComponent::Cpu,
            physical_addr,
            memory_bus::AccessType::Read,
            T::width(),
            memory_bus::BusPriority::CpuData,
            self.cycle_counter,
            None,
        );

        // Get access latency from memory bus
        let latency = self.memory_bus.get_access_latency(
            physical_addr,
            T::width(),
            memory_bus::BusComponent::Cpu,
        );

        // XXX Shouldn't we set dma_timing_penalty to 0 once we've "ticked" it? Mednafen doesn't do
        // it but I don't understand why not. Maybe it's just that the DMA is updated often enough
        // that it doesn't matter because the timing penalty is updated constantly?
        self.tick(self.dma_timing_penalty + latency);

        if let Some(offset) = map::RAM.contains(abs_addr) {
            // Check cache coherency
            if self.cache_coherency.needs_invalidation(memory_bus::CacheType::Data) {
                self.cache_system.invalidate_dcache();
                self.cache_coherency.mark_synchronized(memory_bus::CacheType::Data);
            }
            return self.xmem.ram_load(offset);
        }

        if let Some(offset) = map::BIOS.contains(abs_addr) {
            // XXX Mednafen doesn't add any penalty for BIOS read, which sounds wrong. It's
            // probably not a common-enough occurence to matter
            return self.xmem.bios_load(offset);
        }

        if let Some(offset) = map::SPU.contains(abs_addr) {
            if T::width() == AccessWidth::Word {
                self.tick(36);
            } else {
                self.tick(16);
            }

            return spu::load(self, offset);
        }

        if let Some(offset) = map::DMA.contains(abs_addr) {
            self.tick(1);
            return dma::load(self, offset);
        }

        if let Some(offset) = map::TIMERS.contains(abs_addr) {
            self.tick(1);
            return timers::load(self, offset);
        }

        if let Some(offset) = map::GPU.contains(abs_addr) {
            self.tick(1);
            return gpu::load(self, offset);
        }

        if let Some(offset) = map::MDEC.contains(abs_addr) {
            self.tick(1);
            return mdec::load(self, offset);
        }

        if let Some(offset) = map::PAD_MEMCARD.contains(abs_addr) {
            self.tick(1);
            // TODO
            return pad_memcard::load(self, offset);
        }

        if let Some(offset) = map::CDROM.contains(abs_addr) {
            self.tick(6 * T::width() as i32);
            return cd::load(self, offset);
        }

        if let Some(off) = map::IRQ_CONTROL.contains(abs_addr) {
            self.tick(1);

            let v = match off {
                0 => u32::from(irq::status(self)),
                4 => u32::from(irq::mask(self)),
                _ => {
                    warn!("Unhandled IRQ load at address {:08x}, returning 0", abs_addr);
                    0
                }
            };

            // Since the IRQ registers are only 16bit wide the high 32bits are undefined. In
            // practice the high bits appear to maintain the value of the previous load.
            //
            // We could try to emulate this behaviour by keeping track of the previously loaded
            // value and use that but it's unclear if any game relies on this edge case.
            //
            // So why 0x1f80 in the high bits?
            //
            // In the BIOS IRQ handler just before loading the value of the mask the code loads the
            // base address of the IRQ handler (0x1f801070) then does an LW of the mask (base + 4).
            // In this case the load will return 0x1f80 in the high 16 bits.
            //
            // So any code that does "load IRQ register address -> load IRQ register" in sequence
            // will have 1f80 in the high bits, so it's a sane default.
            return Addressable::from_u32(v | 0x1f80_0000);
        }

        if let Some(offset) = map::SCRATCH_PAD.contains(abs_addr) {
            // Scratchpad can be accessed during DMA without penalty
            // This is crucial for games that use scratchpad for critical data during DMA
            self.tick(1);
            return self.scratch_pad.load(offset);
        }

        if let Some(offset) = map::EXPANSION_1.contains(abs_addr) {
            // Expansion port region 1
            return self.expansion.load(offset);
        }

        if map::CACHE_CONTROL.contains(abs_addr).is_some() {
            if T::width() != AccessWidth::Word {
                panic!("Unhandled cache control access");
            }

            return Addressable::from_u32(self.cache_control);
        }

        if let Some(offset) = map::MEM_CONTROL.contains(abs_addr) {
            if T::width() != AccessWidth::Word {
                panic!("Unhandled MEM_CONTROL {:?} access", T::width());
            }

            let index = (offset >> 2) as usize;

            return Addressable::from_u32(self.mem_control[index]);
        }

        if map::RAM_SIZE.contains(abs_addr).is_some() {
            if T::width() != AccessWidth::Word {
                panic!("Unhandled RAM_SIZE access");
            }

            return Addressable::from_u32(self.ram_size);
        }

        // Log warning and return a safe default value instead of panicking
        warn!("Unhandled load at address {:08x}, returning 0xdeadbeef", abs_addr);
        Addressable::from_u32(0xdeadbeef)
    }

    /// Decode `address` and perform the store to the target module
    fn store<T: Addressable>(&mut self, address: u32, val: T) {
        let abs_addr = map::mask_region(address);

        // Apply memory mirroring
        let physical_addr = self.memory_bus.apply_mirroring(abs_addr);

        // Submit memory request to unified bus
        self.memory_bus.request_access(
            memory_bus::BusComponent::Cpu,
            physical_addr,
            memory_bus::AccessType::Write,
            T::width(),
            memory_bus::BusPriority::CpuData,
            self.cycle_counter,
            Some(val.as_u32()),
        );

        // Invalidate caches on write
        self.cache_coherency.invalidate_on_write(physical_addr, memory_bus::BusComponent::Cpu);

        // Get access latency
        let latency = self.memory_bus.get_access_latency(
            physical_addr,
            T::width(),
            memory_bus::BusComponent::Cpu,
        );
        self.tick(latency);

        if let Some(offset) = map::RAM.contains(abs_addr) {
            self.xmem.ram_store(offset, val);
            return;
        }

        if let Some(offset) = map::SCRATCH_PAD.contains(abs_addr) {
            return self.scratch_pad.store(offset, val);
        }

        if let Some(offset) = map::SPU.contains(abs_addr) {
            spu::store(self, offset, val);
            return;
        }

        if let Some(offset) = map::DMA.contains(abs_addr) {
            dma::store(self, offset, val);
            return;
        }

        if let Some(offset) = map::TIMERS.contains(abs_addr) {
            timers::store(self, offset, val);
            return;
        }

        if let Some(offset) = map::GPU.contains(abs_addr) {
            gpu::store(self, offset, val);
            return;
        }

        if let Some(offset) = map::MDEC.contains(abs_addr) {
            mdec::store(self, offset, val);
            return;
        }

        if let Some(offset) = map::PAD_MEMCARD.contains(abs_addr) {
            pad_memcard::store(self, offset, val);
            return;
        }

        if let Some(offset) = map::CDROM.contains(abs_addr) {
            cd::store(self, offset, val);
            return;
        }

        if let Some(offset) = map::IRQ_CONTROL.contains(abs_addr) {
            match offset {
                0 => irq::ack(self, val.as_u16()),
                4 => irq::set_mask(self, val.as_u16()),
                _ => {
                    warn!("Unhandled IRQ store at address {:08x}, ignoring", abs_addr);
                }
            }

            return;
        }

        if let Some(offset) = map::EXPANSION_1.contains(abs_addr) {
            // Expansion port region 1
            self.expansion.store(offset, val);
            return;
        }

        if let Some(offset) = map::MEM_CONTROL.contains(abs_addr) {
            if T::width() != AccessWidth::Word {
                panic!("Unhandled MEM_CONTROL {:?} access", T::width());
            }

            let val = val.as_u32();

            // We don't actually implement those registers, we assume that all BIOSes and games are
            // going to use the default memory configuration. I'm not aware of any game that breaks
            // this assumption. Still, we can catch any attempt at using a non-standard
            // configuration and report an error.
            match offset {
                // Expansion 1 base address
                0 => {
                    if val != 0x1f00_0000 {
                        panic!("Bad expansion 1 base address: 0x{:08x}", val);
                    }
                }
                // Expansion 2 base address
                4 => {
                    if val != 0x1f80_2000 {
                        panic!("Bad expansion 2 base address: 0x{:08x}", val);
                    }
                }
                _ => (),
            }

            let index = (offset >> 2) as usize;
            self.mem_control[index] = val;
            return;
        }

        if map::CACHE_CONTROL.contains(abs_addr).is_some() {
            if T::width() != AccessWidth::Word {
                panic!("Unhandled cache control access");
            }

            self.cache_control = val.as_u32();

            return;
        }

        if map::RAM_SIZE.contains(abs_addr).is_some() {
            if T::width() != AccessWidth::Word {
                panic!("Unhandled RAM_SIZE access");
            }

            self.ram_size = val.as_u32();
            return;
        }

        if let Some(offset) = map::EXPANSION_2.contains(abs_addr) {
            warn!("Unhandled write to expansion 2 register {:x}", offset);
            return;
        }

        panic!(
            "Unhandled store at address {:08x} (val=0x{:08x})",
            abs_addr,
            val.as_u32()
        );
    }

    /// Returns true if the instruction cache is enabled in the CACHE_CONTROL register
    fn icache_enabled(&self) -> bool {
        self.cache_control & 0x800 != 0
    }

    /// Returns true if the cache is in "tag test mode"
    fn tag_test_mode(&self) -> bool {
        self.cache_control & 4 != 0
    }

    fn set_dma_timing_penalty(&mut self, penalty: CycleCount) {
        // XXX This is from mednafen and it's hacky. Basically since we store the `free_cycles` in
        // u8 we can't stall the CPU for more than 255 cycles or it'll overflow. The reason this
        // limitation at 200 doesn't break everything is because the DMA is refreshed very often
        // and it will call this method again with the remainder of the penalty as long as it
        // exists. It's still very ugly...
        self.dma_timing_penalty = min(penalty, 200);
    }

    fn set_cpu_stalled_for_dma(&mut self, stalled: bool) {
        self.cpu_stalled_for_dma = stalled;
    }

    /// Initialize GGPO netplay session
    pub fn init_netplay(&mut self, config: ggpo::NetplayConfig) -> Result<()> {
        let session = ggpo::GgpoSession::new(config)?;
        self.ggpo_session = Some(session);
        Ok(())
    }

    /// Connect to netplay session
    pub async fn connect_netplay(&mut self) -> Result<()> {
        if let Some(ref mut session) = self.ggpo_session {
            session.connect().await?;
        }
        Ok(())
    }

    /// Process netplay frame
    pub fn process_netplay_frame(&mut self, local_input: u32) -> Result<()> {
        if let Some(ref mut session) = self.ggpo_session {
            let input_frame = ggpo::InputFrame {
                frame: session.get_current_frame(),
                player_id: 1,
                buttons: local_input,
                analog_left_x: 128,
                analog_left_y: 128,
                analog_right_x: 128,
                analog_right_y: 128,
                checksum: self.calculate_game_checksum(),
            };

            session.advance_frame(input_frame)?;

            // Save current state for potential rollback
            let state = self.create_save_state()?;
            session.save_frame(state)?;
        }
        Ok(())
    }

    /// Create a save state for rollback
    pub fn create_save_state(&self) -> Result<crate::save_state::SaveState> {
        use crate::save_state::*;

        let cpu_state = CpuState {
            pc: self.cpu.pc(),
            next_pc: self.cpu.next_pc(),
            regs: self.cpu.regs(),
            hi: self.cpu.hi(),
            lo: self.cpu.lo(),
            cop0_regs: self.cop0.regs(),
            load_delay_slot: self.cpu.load_delay_slot(),
            branch_delay: self.cpu.branch_delay(),
            exception_pending: self.cpu.exception_pending(),
        };

        let gpu_state = GpuState {
            vram: self.gpu.vram().to_vec(),
            display_mode: self.gpu.display_mode(),
            display_area: DisplayArea {
                x: self.gpu.display_area_x(),
                y: self.gpu.display_area_y(),
                width: self.gpu.display_width(),
                height: self.gpu.display_height(),
            },
            draw_area: DrawArea {
                left: self.gpu.draw_area_left(),
                top: self.gpu.draw_area_top(),
                right: self.gpu.draw_area_right(),
                bottom: self.gpu.draw_area_bottom(),
            },
            texture_window: TextureWindow {
                mask_x: self.gpu.texture_window_mask_x(),
                mask_y: self.gpu.texture_window_mask_y(),
                offset_x: self.gpu.texture_window_offset_x(),
                offset_y: self.gpu.texture_window_offset_y(),
            },
            draw_offset: self.gpu.draw_offset(),
            mask_settings: self.gpu.mask_settings(),
            status_register: self.gpu.status(),
        };

        let spu_state = SpuState {
            voices: vec![],
            control_register: self.spu.control_register(),
            status_register: self.spu.status_register(),
            reverb_settings: ReverbSettings::default(),
            volume_left: self.spu.main_volume_left(),
            volume_right: self.spu.main_volume_right(),
            cd_volume_left: self.spu.cd_volume_left(),
            cd_volume_right: self.spu.cd_volume_right(),
            ram: self.spu.ram().to_vec(),
        };

        let memory_state = MemoryState {
            main_ram: self.xmem.ram().to_vec(),
            scratchpad: self.scratch_pad.data().to_vec(),
            bios: self.xmem.bios().to_vec(),
            memory_cards: [None, None],
        };

        let controller_state = ControllerState::default();

        let timing_state = TimingState {
            system_clock: self.cycle_counter as u64,
            gpu_clock: 0,
            spu_clock: 0,
            timers: [TimerState::default(); 3],
            frame_counter: 0,
        };

        let mut state = SaveState::new();
        state.cpu_state = cpu_state;
        state.gpu_state = gpu_state;
        state.spu_state = spu_state;
        state.memory_state = memory_state;
        state.controller_state = controller_state;
        state.timing_state = timing_state;

        Ok(state)
    }

    /// Load a save state for rollback
    pub fn load_save_state(&mut self, state: &crate::save_state::SaveState) -> Result<()> {
        // Restore CPU state
        self.cpu.set_pc(state.cpu_state.pc);
        self.cpu.set_next_pc(state.cpu_state.next_pc);
        self.cpu.set_regs(state.cpu_state.regs);
        self.cpu.set_hi(state.cpu_state.hi);
        self.cpu.set_lo(state.cpu_state.lo);
        self.cop0.set_regs(state.cpu_state.cop0_regs);

        // Restore memory
        self.xmem.set_ram(&state.memory_state.main_ram);
        self.scratch_pad.set_data(&state.memory_state.scratchpad);

        // Restore timing
        self.cycle_counter = state.timing_state.system_clock as CycleCount;

        Ok(())
    }

    /// Calculate checksum for sync verification
    fn calculate_game_checksum(&self) -> u32 {
        use crc32fast::Hasher;
        let mut hasher = Hasher::new();
        
        // Hash critical game state
        hasher.update(&self.cpu.pc().to_le_bytes());
        hasher.update(&self.cpu.regs()[0..8].iter().flat_map(|r| r.to_le_bytes()).collect::<Vec<_>>());
        
        hasher.finalize()
    }

    /// Disconnect netplay session
    pub fn disconnect_netplay(&mut self) {
        if let Some(ref mut session) = self.ggpo_session {
            session.disconnect();
        }
        self.ggpo_session = None;
    }

    /// Check if netplay is active
    pub fn is_netplay_active(&self) -> bool {
        self.ggpo_session.is_some()
    }

    /// Get netplay statistics
    pub fn get_netplay_stats(&self) -> Option<ggpo::network::NetworkStats> {
        self.ggpo_session.as_ref().map(|s| s.get_network_stats())
    }
}

/// Types of access supported by the PlayStation architecture
#[derive(PartialEq, Eq, Debug)]
pub enum AccessWidth {
    Byte = 1,
    HalfWord = 2,
    Word = 4,
}

/// rait representing the attributes of a primitive addressable
/// memory location.
pub trait Addressable {
    /// Retrieve the width of the access
    fn width() -> AccessWidth;
    /// Build an Addressable value from an u32. If the Addressable is 8 or 16bits wide the MSBs are
    /// discarded to fit.
    fn from_u32(i: u32) -> Self;
    /// Retrieve the value of the Addressable as an u32. If the Addressable is 8 or 16bits wide the
    /// MSBs are padded with 0s.
    fn as_u32(&self) -> u32;
    /// Retrieve the value of the Addressable as an u16. If the Addressable was 8 bit wide the MSBs
    /// are padded with 0s, if it was 32bit wide the MSBs are truncated.
    fn as_u16(&self) -> u16 {
        self.as_u32() as u16
    }
    /// Retrieve the value of the Addressable as an u8. If the Addressable was 16 or 32bit wide the
    /// MSBs are truncated.
    fn as_u8(&self) -> u8 {
        self.as_u32() as u8
    }
}

impl Addressable for u8 {
    fn width() -> AccessWidth {
        AccessWidth::Byte
    }

    fn from_u32(v: u32) -> u8 {
        v as u8
    }

    fn as_u32(&self) -> u32 {
        u32::from(*self)
    }
}

impl Addressable for u16 {
    fn width() -> AccessWidth {
        AccessWidth::HalfWord
    }

    fn from_u32(v: u32) -> u16 {
        v as u16
    }

    fn as_u32(&self) -> u32 {
        u32::from(*self)
    }
}

impl Addressable for u32 {
    fn width() -> AccessWidth {
        AccessWidth::Word
    }

    fn from_u32(v: u32) -> u32 {
        v
    }

    fn as_u32(&self) -> u32 {
        *self
    }
}

/// Scratch Pad (data cache used as fast RAM)
#[derive(serde::Serialize, serde::Deserialize)]
struct ScratchPad {
    #[serde(with = "serde_big_array::BigArray")]
    data: [u8; SCRATCH_PAD_SIZE],
}

impl ScratchPad {
    /// Instantiate Scratch Pad
    pub fn new() -> ScratchPad {
        ScratchPad {
            data: [0; SCRATCH_PAD_SIZE],
        }
    }

    /// Fetch the little endian value at `offset`
    pub fn load<T: Addressable>(&self, offset: u32) -> T {
        // The two MSBs are ignored, the 2MB RAM is mirrored four times over the first 8MB of
        // address space
        let offset = (offset & 0x1f_ffff) as usize;

        let mut v = 0;

        for i in 0..T::width() as usize {
            let b = u32::from(self.data[offset + i]);

            v |= b << (i * 8)
        }

        Addressable::from_u32(v)
    }

    /// Store the 32bit little endian word `val` into `offset`
    pub fn store<T: Addressable>(&mut self, offset: u32, val: T) {
        // The two MSBs are ignored, the 2MB RAM is mirrored four times over the first 8MB of
        // address space
        let offset = (offset & 0x1f_ffff) as usize;

        let val = val.as_u32();

        for i in 0..T::width() as usize {
            self.data[offset + i] = (val >> (i * 8)) as u8;
        }
    }
}

/// Scratch Pad (data cache): 1KB
const SCRATCH_PAD_SIZE: usize = 1024;

pub mod map {
    //! PlayStation memory map

    /// Mask array used to strip the region bits of the address. The mask is selected using the 3
    /// MSBs of the address so each entry effectively matches 512kB of the address space. KSEG2 is
    /// not touched since it doesn't share anything with the other regions.
    const REGION_MASK: [u32; 8] = [
        // KUSEG: 2048MB
        0xffff_ffff,
        0xffff_ffff,
        0xffff_ffff,
        0xffff_ffff,
        // KSEG0:  512MB
        0x7fff_ffff,
        // KSEG1:  512MB
        0x1fff_ffff,
        // KSEG2: 1024MB
        0xffff_ffff,
        0xffff_ffff,
    ];

    /// Mask a CPU address to remove the region bits.
    pub fn mask_region(addr: u32) -> u32 {
        // Index address space in 512MB chunks
        let index = (addr >> 29) as usize;

        addr & REGION_MASK[index]
    }

    pub struct Range(u32, u32);

    impl Range {
        /// Return `Some(offset)` if addr is contained in `self`
        pub fn contains(self, addr: u32) -> Option<u32> {
            let Range(start, length) = self;

            if addr >= start && addr < start + length {
                Some(addr - start)
            } else {
                None
            }
        }
    }

    /// Main RAM: 2MB mirrored four times over the first 8MB
    pub const RAM: Range = Range(0x0000_0000, 8 * 1024 * 1024);

    /// Expansion region 1
    pub const EXPANSION_1: Range = Range(0x1f00_0000, 512 * 1024);

    /// BIOS ROM. Read-only, significantly slower to access than system RAM
    pub const BIOS: Range = Range(0x1fc0_0000, 512 * 1024);

    /// ScratchPad: data cache used as a fast 1kB RAM
    pub const SCRATCH_PAD: Range = Range(0x1f80_0000, 1024);

    /// Memory latency and expansion mapping
    pub const MEM_CONTROL: Range = Range(0x1f80_1000, 36);

    /// Gamepad and memory card controller
    pub const PAD_MEMCARD: Range = Range(0x1f80_1040, 32);

    /// Register that has something to do with RAM configuration, configured by the BIOS
    pub const RAM_SIZE: Range = Range(0x1f80_1060, 4);

    /// Interrupt Control registers (status and mask)
    pub const IRQ_CONTROL: Range = Range(0x1f80_1070, 8);

    /// Direct Memory Access registers
    pub const DMA: Range = Range(0x1f80_1080, 0x80);

    /// Timer registers
    pub const TIMERS: Range = Range(0x1f80_1100, 0x30);

    /// CDROM controller
    pub const CDROM: Range = Range(0x1f80_1800, 4);

    /// GPU Registers
    pub const GPU: Range = Range(0x1f80_1810, 8);

    /// MDEC registers
    pub const MDEC: Range = Range(0x1f80_1820, 8);

    /// SPU registers
    pub const SPU: Range = Range(0x1f80_1c00, 640);

    /// Expansion region 2
    pub const EXPANSION_2: Range = Range(0x1f80_2000, 66);

    /// Cache control register. Full address since it's in KSEG2
    pub const CACHE_CONTROL: Range = Range(0xfffe_0130, 4);
}
